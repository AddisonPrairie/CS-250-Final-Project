\documentclass[11pt]{article}


\usepackage{preamble}

\title{Error Correcting Codes, Hardness Amplification and Boosting.}
\date{}

\begin{document}
    
\noindent Error Correcting Codes, Hardness Amplification and Boosting \hfill  CS 250, Winter 2025\\
\hrule


\section{Introduction}

\tableofcontents


\section{Preliminaries}

\section{Hardness Amplification with ECCs}

\begin{definition}{3.x}
    We say that a function $G : \pmo^\ell \rightarrow \pmo^{n}$ is an $(\ell, n)$-PRG if, for any size $n$ circuit $C$ over $n$ inputs, 
    \begin{equation*}
        \left|\Pr_{x \backsim U_n}[C(x)] - \Pr_{x \backsim U_s}[C(G(s))]\right| < \frac{1}{10}.
    \end{equation*}
\end{definition}

The parameter $\ell$ is the seed length.

\begin{assumption}{1} \label{a-1}
    There exists a function $f : \pmon \rightarrow \pmo$ such that $f$ can be computed in time $2^{O(n)}$, but there exists some $\delta > 0$ such that 
    \begin{equation*}
        \Corr\left(f, 2^{\delta n}\right) < 1.
    \end{equation*}
\end{assumption}

\begin{assumption}{2} \label{a-2}
    There exists a function $f : \pmon \rightarrow \pmo$ such that $f$ can be computed in time $2^{O(n)}$, but there exists some $\delta > 0$ such that 
    \begin{equation*}
        \Corr\left(f, 2^{\delta n}\right) < .9.
    \end{equation*}
\end{assumption}

\begin{assumption}{3} \label{a-3}
    There exists a function $f : \pmon \rightarrow \pmo$ such that $f$ can be computed in time $2^{O(n)}$, but there exists some $\delta > 0$ such that 
    \begin{equation*}
        \Corr\left(f, 2^{\delta n}\right) < 2^{-\Omega(n)}.
    \end{equation*}
\end{assumption}

We will prove that, given a worst case hard function $f$, we can transform it into an average case $f'$.

\begin{theorem}{3.x} If there exists a function $f$ satisfying the worst case hardness assumption, there exists a function $f'$ satisfying the average case hardness assumption.

\end{theorem}

\subsection{Why Hardness Amplification?}

\begin{theorem}{3.x} Suppose that $G$ is a $(O(\log n), n)$-PRG computable in $\poly(n)$ time. Then $\P = \BPP$.
\end{theorem}

\subsubsection{A Simple PRG}

\begin{theorem}{3.x}
    Given the average case hardness assumption, there exists a $(n - 1, n)$-PRG.
\end{theorem}

\subsubsection{The Nisan-Wigderson Generator}

\begin{theorem}{3.x}
    Given the average case hardness assumption, there exists a $(O(\log n), n)$-PRG.
\end{theorem}

\begin{center}
    \begin{tikzpicture}[align=center,node distance=4cm, scale=1.5]
        \node[circle, inner sep=0pt, minimum size=15pt] (1) at (1, 0) {$s_1$}; 
        \node[circle, inner sep=0pt, minimum size=15pt] (2) at (2, 0) {$s_2$};
        \node[circle, inner sep=0pt, minimum size=15pt] (3) at (3, 0) {$s_3$};
        \node[circle, inner sep=0pt, minimum size=15pt] (4) at (4, 0) {$s_4$};
        \node[] (5) at (5, 0) {$\cdots$};
        \node[circle, inner sep=0pt, minimum size=15pt] (6) at (6, 0) {$s_{\ell}$};

        \node[] (11) at (.5, 2.5) {$S_1$};
        \draw[] (1.north) -- (11.south);
        \draw[] (3.north) -- (11.south);
        \draw[] (5.north) -- (11.south);

        \node[] (21) at (.5, 3.5) {$f(S_1)$};

        \draw[->] (11) -- (21);


        \node[] (12) at (1.5, 2.5) {$S_2$};
        \draw[] (2.north) -- (12.south);
        \draw[] (3.north) -- (12.south);
        \draw[] (6.north) -- (12.south);

        \node[] (22) at (1.5, 3.5) {$f(S_2)$};

        \draw[->] (12) -- (22);


        \node[] (13) at (2.5, 2.5) {$S_3$};
        \draw[] (1.north) -- (13.south);
        \draw[] (4.north) -- (13.south);
        \draw[] (6.north) -- (13.south);

        \node[] (23) at (2.5, 3.5) {$f(S_3)$};

        \draw[->] (13) -- (23);


        \node[] (14) at (3.5, 2.5) {$S_4$};
        \draw[] (2.north) -- (14.south);
        \draw[] (4.north) -- (14.south);
        \draw[] (5.north) -- (14.south);

        \node[] (24) at (3.5, 3.5) {$f(S_4)$};

        \draw[->] (14) -- (24);


        \node[] (15) at (5, 2.5) {$\cdots$};
        \draw[] (4.north) -- (15.south);
        \draw[] (2.north) -- (15.south);
        \draw[] (6.north) -- (15.south);

        \node[] (25) at (5, 3.5) {$\cdots$};

        \draw[->] (15) -- (25);

        \node[] (16) at (6.5, 2.5) {$S_n$};
        \draw[] (3.north) -- (16.south);
        \draw[] (5.north) -- (16.south);
        \draw[] (6.north) -- (16.south);

        \node[] (26) at (6.5, 3.5) {$f(S_n)$};

        \draw[->] (16) -- (26);

        \draw [decorate,decoration={brace,amplitude=5pt}]
  (0.25,3.75) -- (6.75,3.75) node[midway, yshift=.5cm]{$G(s)$};

        \draw[decorate, decoration={brace,amplitude=5pt, mirror}] 
        (.75, -.2) -- (6.25, -.2) node[midway, yshift=-.5cm]{$s$};
    \end{tikzpicture}
\end{center}

\subsection{Worst Case Hardness to Mild Hardness}

\newpage

\begin{theorem}{3.x}
    Suppose that $\cC$ is an $[m^2, m, .1]_2$ code which is computable in $\poly(m)$ time and locally decodable in $\polylog (m)$ time. Then if $f$ satisfies the worst case hardness assumption, $\cC \concat f$ satisfies the mild hardness assumption.
\end{theorem}

\begin{proof}
    Suppose that $f : \pmon \rightarrow \pmo$ satisfies the worst case hardness assumption, so that $f$ can be computed in time $2^{O(n)}$ yet, for some $\delta > 0$, $\Corr(f, 2^{\delta n}) < 1$. Writing $N = 2^n$, we can encode $f$ as a string $\TT(f) \in \pmo^{N}$ as its truth table. Then encoding $\TT(f)$ using $\cC$ to a string of length $N^2 = 2^{2n}$, we get can view this as a truth table for a function $\hat{f} : \pmo^{2n} \rightarrow \pmo$. We claim that if $f$ satisfies the worst case hardness assumption, $\hat{f}$ satisfies the mild hardness assumption. To prove that $\Corr(\hat{f}, 2^{n\delta/2}) \leq .9$, suppose for the sake of contradiction that $C$ is a circuit of size $2^{n \delta /2}$ with $\Corr(\hat{f}, C) > .9$. We will use this $C$ to construct a circuit $C'$ of size $S$ compute our original $f$ perfectly. First, consider the truth table $\TT(C)$ of the function computed by the circuit $C$. Because $\Corr(\hat{f}, C) > .9$, the string $\TT(C)$ and $\TT(\hat{f})$ have relative distance $\delta(\TT(C), \TT(\hat{f})) < .05$, which is less than half the distance of the code $\cC$. Since $\TT(\hat{f})$ is the encoding of $\TT(f)$ under the code $\cC$, we can recover $\TT(f)$ from $\TT(C)$.

    Suppose that $\LDec$ is the local decoder for $\cC$ running in $\polylog(N) = \poly(n)$ time. Consider the following randomized circuit $C_{\sfrac{2}{3}}$ for computing $f(x)$.

    \parbox{.4\linewidth}{%
        \begin{center}
            \begin{tikzpicture}

                \draw [decorate,decoration={brace,amplitude=7.5pt}]
        (0, .15) -- (4, 0.15) node[midway, yshift=.5cm]{$\TT(C)$};

                \draw[] (0, -.1) rectangle (4, .1);

                \draw[] (.2, -.2) -- (.2, -.4) -- (2, -.4);
                \draw[fill=white] (.2, -.2) circle (.05cm);
                \draw[] (1.5, -.2) -- (1.5, -.4);
                \draw[fill=white] (1.5, -.2) circle (.05cm);
                \draw[] (3.5, -.2) -- (3.5, -.4) -- (2, -.4);
                \draw[fill=white] (3.5, -.2) circle (.05cm);
                \draw[] (2.7, -.2) -- (2.7, -.4);
                \draw[fill=white] (2.7, -.2) circle (.05cm);

                \draw[->] (2, -.4) -- (2, -.6);

                \node[] at (2, -.8) {$\LDec$};

                

                \draw[] (.2, -2) -- (.2, -2.2) -- (2, -2.2);
                \draw[fill=white] (.2, -2) circle (.05cm);
                \node[] at (.2, -1.75) {$C$};
                \draw[] (1.5, -2) -- (1.5, -2.2);
                \draw[fill=white] (1.5, -2) circle (.05cm);
                \node[] at (1.5, -1.75) {$C$};
                \draw[] (3.5, -2) -- (3.5, -2.2) -- (2, -2.2);
                \draw[fill=white] (3.5, -2) circle (.05cm);
                \node[] at (3.5, -1.75) {$C$};
                \draw[] (2.7, -2) -- (2.7, -2.2);
                \draw[fill=white] (2.7, -2) circle (.05cm);
                \node[] at (2.7, -1.75) {$C$};

                \draw[->] (2, -2.2) -- (2, -2.4);

                \node[] at (2, -2.6) {$\LDec$};
            \end{tikzpicture}
        \end{center}
    }
    \hfill
    \parbox{.5\linewidth}{%
        \textbf{Input:} $x \in \pmo^n$
        \begin{enumerate}
            \item Compute $i$ such that $x$ is the $i$-th evaluation point in the truth table of $f$.
            \item Return $\LDec^{\TT(C)}(i)$ using $C$ to simulate queries to $\TT(C)$.
        \end{enumerate}
    }

    The size of $C_{\sfrac{1}{3}}$ is determined by the running time of $\LDec$ and the number of queries it makes to $\TT(C)$, both of which are polynomial in $n$. For each query that the local decoder $\LDec$ makes to $\TT(C)$, we'll need a copy of $C$ to compute this entry in the truth table; thus, the total size of $C_{\sfrac{1}{3}}$ is 
    \begin{equation*}
        |C_{\sfrac{1}{3}}| = \poly(n) \cdot |C| + \poly(n).
    \end{equation*}
    By the guarantees of our local decoding algorithm, for any input $x \in \pmon$, $\Pr[C_{\sfrac{1}{3}}(x) \neq f(x)] \leq \sfrac{1}{3}$, where this probability is over the random bits used by $C_{\sfrac{1}{3}}$. Since our goal is to compute $f$ perfectly, we can amplify the success probability by taking the majority over $O(n)$ copies of $C_{\sfrac{1}{3}}$ using independent random bits. This yields a circuit $C_{2^{-n}}$ of size $O(n \cdot |C_{\sfrac{1}{3}}|)$ such that $\Pr[C_{2^{-n}}(x) \neq f(x)] < 2^{-n}$. For a given setting of random bits $r$, write $C_{2^{-n}}^{(r)}$ to be a deterministic copy of $C_{2^{-n}}$ with fixed random bits. Then we can apply the union bound find to see
    \begin{equation*}
        \Pr_r\left[C^{(r)}_{2^{-n}}(x) = f(x) \text{ for all $x$}\right] \geq 1 - \sum_{x \in \pmon} \Pr_r\left[C^{(r)}_{2^{-n}}(x) = f(x)\right] > 1 - 2^{n} \cdot 2^{-n} = 0.
    \end{equation*}
    Thus, there must exist a particular $r$ such that $C^{(r)}_{2^{-n}}$ computes $f$ exactly. Note that the size of this circuit is 
    \begin{equation*}
        \left|C^{(r)}_{2^{-n}}\right| \leq O\left(n \cdot \poly(n) \cdot |C|\right) = \poly(n) \cdot 2^{\delta n / 2} \leq 2^{\delta n}.
    \end{equation*}
    However, this contradicts the fact that $\Corr(f, 2^{\delta n}) < 1$. Thus, $\Corr(\hat{f}, 2^{n\delta / 2}) \leq .9$. Note also that $\hat{f}$ will still be computable in time $2^{O(n)}$. Thus $\hat{f}$ satisfies the mild hardness assumption.
\end{proof}

\subsubsection{Reed-Muller and Hadamard Codes}

Thus, we have reduced the task of hardness amplification to finding a suitable error correcting code. In class, we have seen two locally correctable codes: Reed-Muller codes and Hadamard codes. As a reminder, here are the definitions and parameters of those two codes:

\begin{definition}{3.x}[Reed-Muller Codes]
    Suppose $\F$ is a finite field of size $q$. The Reed-Muller code $\RM_q(m, d)$ is the set of all evaluations of $d$-degree $m$-variate polynomials over $\F_q$,
    \begin{equation*}
        \RM_q(m ,r) = \left\{(f(\gamma_1), f(\gamma_2), \ldots, f(\gamma_{q^m})) : f \in \F_q[X_1, \ldots, X_m], \, \deg (f) \leq d\right\},
    \end{equation*}
    where $\gamma_1, \ldots, \gamma_{q^m}$ is a canonical ordering of $\F_q^m$. This code has dimension $k = \binom{m + d}{d}$, block length $N = q^m$, and relative distance $\delta = 1 - d/ q$.
\end{definition}

We had the following algorithm for locally correcting the Reed-Muller code:

\begin{enumerate}
    \item[Input:] Evaluation point $(\gamma_1, \ldots, \gamma_m) \in \F_q^m$, query access to $g : \F^m \rightarrow \F$ such that $\delta(g, f) \leq \sfrac{1}{7}$ for some codeword $f \in \RM_q(m, r)$.
    \item[Output:] $f(\gamma_1, \ldots, \gamma_m)$ with probability $\geq \sfrac{2}{3}$.
    \item Sample a uniform random $(\tau_1, \ldots, \tau_m) \backsim \F_q^m \setminus \{(0, \ldots, 0)\}$.
    \item Define the line $\ell : \F_q \rightarrow \F_q^m$ by
    \begin{equation*}
        \ell(X) = \left(\gamma_1 + \tau_1 X, \ldots, \gamma_m + \tau_m X\right).
    \end{equation*}
    \item Consider the univariate polynomial degree $d$ polynomial $h(X)$ defined by 
    \begin{equation*}
        h(X) = f(\ell(X)).
    \end{equation*}
    \item Run a Reed-Solomon global decoder on $h(X)$ to obtain $\Tilde{h}(X)$ by querying $g(X)$.
    \item Output $\Tilde{h}(0)$.
\end{enumerate}
Let's try to construct a code matching our requirements from a Reed-Muller code. What factors do we need? For starters, the number of queries our local correction algorithm makes is $q$, the size of the field, so we'll want this to be poly-logarithmic in $n$, say $q = \log^3 n$. We also want the block length $N$ to be $\poly(n)$. Thus, we should take $m = \log n / \log \log n$, so that 
\begin{equation*}
    N = q^n = \left(\log^3 n\right)^{\log n / \log \log n} = 2^{3\log \log n \log n / \log \log n} = 2^{3\log n} = n^3.
\end{equation*}
Next, we need the dimension $k$ to be at least $n$, so that we can encode an entire string of length $n$. See that 
\begin{equation*}
    k = \binom{m + d}{d} = \binom{m + d}{m} \geq \left(\frac{m + d}{m}\right)^{m} \geq \left(\frac{d}{m}\right)^{m}.
\end{equation*}
In this case, we need to take $d = \log^2 n$, so that 
\begin{equation*}
    k \geq \left(\frac{\log^2 n \log \log n}{\log n}\right)^{\log n / \log \log n} \geq \left(\log n\right)^{\log n / \log \log n} \geq n.
\end{equation*}
In this case, the distance is $\delta = 1 - d / q = 1 - 1 / \log n$. To keep things simple, we'll just note that $\delta \geq \sfrac{3}{4}$. Let's call this code, with the parameters above, $\RM$. To summarize, we have that $\RM$ is a $[n^3, n, \sfrac{3}{4}]_\F$ code, where $\F$ is a finite field of size $\log^3 n$. Does this complete our search?

Note quite. For one, this is not a binary code, meaning we cannot apply it quite yet. In order to transform it into a binary code, we can concatenate it with another code which is locally correctible: the Hadamard code.

\begin{definition}{3.x}[Hadamard Codes]
    The Hadamard code $\Had_k \subseteq \pmo^{2^k}$ with parameter $k$ is the subset of truth tables of linear functions from $\pmo^k$ to $\pmo$:
    \begin{equation*}
        \Had_k = \left\{\TT\left(x \mapsto \prod_{i \in S} x_i\right) : S \subseteq [k]\right\}.
    \end{equation*} 
    This code has dimension $k$, block length $2^k$, and relative distance $\delta = \sfrac{1}{2}$.
\end{definition}

Fixing $k = \log |\F|$, we will write $\Had$ for the Hadamard code with parameter $k$. Consider the concatenated code $\cC = \Had \concat \RM$. 

\begin{claim}{3.x}
    The code $\cC = \Had \concat \RM$ is a $[n^4, n, \sfrac{3}{8}]_2$ code.
\end{claim}

\begin{proof}
    First, we know that the distance of the two codes is the product of their individual distances, so we indeed get $\delta = \sfrac{3}{8}$. The dimension of the code is still $n$. To compute the block length, see that every ``bit'' of a codeword $c \in \RM$ will be replaced by a string of length $2^{\log |\F|} = |\F| = \log^3 n$, and so the total length of the resulting word is $n^3 \cdot \log^3 n \leq n^4$.
\end{proof}

Here is a picture of what is going on with our code:

\begin{center}
    \begin{tikzpicture}

        % first row
        \draw [decorate,decoration={brace,amplitude=7.5pt}]
        (-3, 0.15) -- (3, 0.15) node[midway, yshift=.5cm]{$x \in \pmo^n$};

        \draw[] (-3, -.1) rectangle (3, .1);

        \draw[] (-1.5, -.1) -- (-1.5, .1);
        \draw [decorate,decoration={brace,amplitude=4pt, mirror}]
        (-3, -.125) -- (-1.5, -.125) node[midway, yshift=-.4cm]{$f_1 \in \F$};
        
        \node[] at (0, -.5) {$\cdots$};

        \draw[] (1.5, -.1) -- (1.5, .1); 
        \draw [decorate,decoration={brace,amplitude=4pt, mirror}]
        (1.5, -.125) -- (3, -.125) node[midway, yshift=-.4cm]{$f_n \in \F$};

        \draw [decorate,decoration={brace,amplitude=4pt, mirror}]
        (-3, -.75) -- (3, -.75);

        \draw[->] (0, -.9) -- (0, -1.8);
        \node[] at (.65, -1.35) {$\RM(x)$};
    
        % second row
        \draw[] (-4, -2.1) rectangle (4, -1.9);

        \draw[] (-2.5, -2.1) -- (-2.5, -1.9);

        \draw [decorate,decoration={brace,amplitude=4pt, mirror}]
        (-4, -2.125) -- (-2.5, -2.125) node[midway, yshift=-.4cm]{$w_1$};

        \draw[] (-4, -2.2) -- (-6, -3.9);
        \draw[] (-2.5, -2.2) -- (-3, -3.9);

        \draw[->] (-3.5, -2.65) -- (-4.5, -3.8);

        \node[fill=white] at (-4, -3.2) {$\Had(w_1)$};

        \node[] at (0, -2.5) {$\cdots$};

        \draw[] (2.5, -2.1) -- (2.5, -1.9);

        \draw [decorate,decoration={brace,amplitude=4pt, mirror}]
        (2.5, -2.125) -- (4, -2.125) node[midway, yshift=-.4cm]{$w_{n^3}$};

        \draw[] (4, -2.2) -- (6, -3.9);
        \draw[] (2.5, -2.2) -- (3, -3.9);

        \draw[->] (3.5, -2.65) -- (4.5, -3.8);

        \node[fill=white] at (4, -3.2) {$\Had(w_{n^3})$};

        % third row
        \draw[] (-6, -4.1) rectangle (6, -3.9);

        \draw[] (-3, -4.1) -- (-3, -3.9);

        \draw[] (3, -4.1) -- (3, -3.9);

        \draw [decorate,decoration={brace,amplitude=7.5pt, mirror}]
        (-6, -4.15) -- (6, -4.15) node[midway, yshift=-.5cm]{$\Enc(x)\in \pmo^{n^3}$};

    \end{tikzpicture}
\end{center}
We've established that this code has the parameters we need, but we've intentionally been a bit vague on what encoding scheme we will use for our Reed-Muller and Hadamard codes. The reason for this is that, while we've seen that both of these codes are locally \emph{correctable} codes, for Theorem ?? to work, we require locally \emph{decodable} codes. In the case of the Hadamard code, we can recover an algorithm for local decoding from our algorithm for local correcting.

\begin{claim}{3.x}
    The Hadamard code has a local decoder making $2$ queries.
\end{claim}

The reason this works is that the Hadamard code is \emph{systematic}: for every index $i \in [k]$ of a bit in a message, there exists an index $j \in [2^k]$ of a bit in the encoded codeword which is equal to the $i$-th bit in the message. To get a local decoding algorithm for Reed-Muller codes, we need to come up with a way to systematically encode them efficiently. This will be addressed in the next section. For now, lets assume that we have local decoders for both codes. Then we claim we have a local decoder for the concatenated code $\cC$:

\begin{claim}{3.x}
    The code $\cC$ is a $[n^4, n, \sfrac{1}{14}]_2$ code computable in $\poly(n)$ time with a local decoder running in $\polylog(n)$ time.
\end{claim}

\subsubsection{Low Degree Extensions}

Consider that any string $x \in \pmon$ can be viewed as the truth table of a function $f_x : \pmo^{\log n} \rightarrow \pmo$. We want to transform this into into a code word $\hat{f}_x$ in our Reed-Muller code. In this case, the requirements on $\hat{f}_x$ are:
\begin{enumerate}
    \item $\deg(\hat{f}_x) \leq \log^2 n$.
    \item $\hat{f}_x$ is a polynomial over $m$ variables, where we recall $m = \log n / \log \log n$.
\end{enumerate}

Choose a subset $\bH \subseteq \F$ of size $\log \log n$. We will view a string $x \in \pmon$ as the truth table of a function $f : \bH^{m} \rightarrow \pmo$. Since the total size of $\bH$ is $\log \log n$ this is valid. Next, we can extend this to a polynomial $\hat{f}_x : \F^m \rightarrow \F$ as the following:
\begin{equation*}
    \hat{f}_x(y_1, \ldots, y_m) = \sum_{\alpha \in \bH^m}f(\alpha) \cdot \delta_\alpha(y_1, \ldots, y_m),
\end{equation*} 
where the polynomial $\delta_\alpha : \F^m \rightarrow \F$ is defined as 
\begin{equation*}
    \delta_\alpha(y_1, \ldots, y_m) = \prod_{i \in [m]} \prod_{\gamma \neq \alpha_i} (y_i - \gamma). 
\end{equation*}
Note that the degree of this polynomial is 

\subsection{Worst Case Hardness to Average Case Hardness}

Note that in our analysis in Theorem 3.?, we could amplify the hardness of the any function $f$ to $1 - \delta$, where $\delta$ is the relative distance of the code $\cC$ at which we can locally decode it. However, since $\cC$ must be binary, $\delta \leq \sfrac{1}{2}$, and so local decoding can not get us to exponentially small correlation. To break past this barrier, we'll need to use the 

\begin{theorem}{3.x}
    The average case hardness assumption implies the worst case hardness assumption.
\end{theorem}



\section{Boosting and Hardness Amplification}

\subsection{Smooth Boosters and The Hardcore Theorem}

\begin{center}
    \begin{tikzpicture}
        \path[draw] (-6.5, -2) rectangle (-2.5, 2);
        \path[draw,use Hobby shortcut,closed=true, pattern=north east lines]
        (-4,.3) .. (-4.4,.4) .. (-5.6, -.3);
        \node[fill=white] at (-4.6, -.5) {$H_1$};
        \node[] at (-4.5, 2.35) {$C_1$};


        \path[draw] (-2, -2) rectangle (2, 2);
        \path[draw,use Hobby shortcut,closed=true, pattern=north east lines]
        (0,.3) .. (.4,1) .. (.6,1.6) .. (1.4,1.4) .. (1.6, .3);
        \node[fill=white] at (.9, .7) {$H_2$};
        \node[] at (0, 2.35) {$C_2$};

        \path[draw] (2.5, -2) rectangle (6.5, 2);
        \path[draw,use Hobby shortcut,closed=true, pattern=north east lines]
        (4,.3) .. (4.4,.5) .. (5.6, -.3);
        \node[fill=white] at (4.7, -.3) {$H_3$};
        \node[] at (4.5, 2.35) {$C_3$};

        \draw[decorate, decoration={brace,amplitude=5pt, mirror}] 
        (-6.75, -2.25) -- (6.75, -2.25) node[midway, yshift=-.5cm]{};

        \draw[->] (0, -2.4) -- (0, -2.8);

        \path[draw] (-2, -7) rectangle (2, -3);
        \path[draw,use Hobby shortcut,closed=true, pattern=north east lines]
        (-.1,-5) .. (.4,-4.4) .. (1.6, -4.7);
        \node[fill=white] at (.8, -5) {$H$};
    \end{tikzpicture}
\end{center}

\subsection{Boosting via the XOR Lemma}



\end{document}